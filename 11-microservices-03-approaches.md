# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

```
Для обеспечения процесса разработки на основе микросервисной архитектуры, я предлагаю использовать следующее решение:

1. Хранение исходного кода:
   - Использование GitLab для хранения и управления исходным кодом. GitLab предоставляет возможность создания репозиториев для каждого сервиса, а также интегрированные средства для непрерывной интеграции и поставки.

2. Непрерывная интеграция и поставка (CI/CD):
   - Использование GitLab CI/CD для автоматизации процессов сборки, тестирования и развертывания микросервисов. GitLab CI/CD позволяет настраивать сборки как по событиям из системы контроля версий, так и по кнопке с указанием параметров.
   - Для безопасного хранения секретных данных можно использовать встроенные механизмы GitLab для управления переменными окружения. Либо использовать Hashicorp Vault.
   - Для создания шаблонов сборок и кастомных шагов при сборке можно использовать возможности GitLab CI/CD для описания пайплайнов в виде кода (YAML).

3. Дополнительные возможности:
   - Для создания собственных докер-образов для сборки проектов можно использовать GitLab Container Registry, Harbor, Nexus.
   - Для развертывания агентов сборки на собственных серверах можно использовать возможности GitLab Runner.
   - Для параллельного запуска нескольких сборок и тестов можно настроить соответствующие параметры в GitLab CI/CD.
4. В качестве облака можно использовать Azure, Google Cloud, Yandex Cloud.
```

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

```
1. Центральное хранилище логов:
   - Elasticsearch как центральное хранилище логов. Elasticsearch обеспечивает масштабируемое хранение и быстрый поиск логов.
   - Logstash для сбора, обработки и отправки логов в Elasticsearch. Logstash позволяет принимать логи из различных источников, обрабатывать их и направлять в центральное хранилище.
   - Kibana для визуализации и анализа логов. Kibana предоставляет пользовательский интерфейс для поиска, фильтрации и визуализации данных из Elasticsearch.

2. Агенты для сбора логов:
   - Filebeat для сбора логов из stdout на каждом хосте. Filebeat является легковесным агентом, который может быть установлен на каждом хосте для сбора логов и отправки их в Logstash.

3. Гарантированная доставка логов:
   - Для гарантированной доставки логов до центрального хранилища можно настроить механизмы повторной отправки в случае ошибок, а также мониторинг состояния агентов с помощью метрик.

4. Поиск и фильтрация логов:
   - Elasticsearch обеспечивает возможность выполнения сложных запросов для поиска и фильтрации логов по различным параметрам.
   - Kibana предоставляет удобный интерфейс для создания запросов, фильтрации данных и визуализации результатов.

5. Предоставление доступа разработчикам:
   - Разработчики могут получить доступ к Kibana для поиска по записям логов, просмотра статистики и анализа производительности своих сервисов.

6. Сохранение поисков:
   - Kibana позволяет сохранять запросы и фильтры для последующего использования, а также генерировать ссылки на сохраненные поисковые запросы.
   ```
## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

```
Для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре я предлагаю использовать следующее решение:

1. Prometheus для сбора метрик:
   - Prometheus - система мониторинга и алертинга, способная собирать метрики из различных источников, включая хосты и сервисы.
   - Node Exporter для сбора метрик с хостов: Node Exporter является агентом, который собирает информацию о ресурсах хоста, таких как CPU, RAM, HDD, Network, и предоставляет ее в формате, понятном Prometheus.
   - Exporter для сбора метрик отдельных сервисов: Для каждого сервиса можно написать свой экспортер, который будет собирать специфичные метрики и предоставлять их Prometheus.

2. Grafana для визуализации и анализа метрик:
   - Grafana - платформа для визуализации данных из различных источников, включая Prometheus.
   - Grafana позволяет создавать гибкие дашборды с различными панелями, графиками и таблицами для отслеживания состояния системы.
   - Пользовательский интерфейс Grafana обладает широкими возможностями по настройке запросов к данным и агрегированию информации для анализа.

3. Алертинг и уведомления:
   - Prometheus позволяет настраивать правила для определения аномалий и отправки уведомлений в случае превышения пороговых значений.
   - Графана также поддерживает интеграцию с различными системами уведомлений для оперативного реагирования на проблемы.

4. Масштабируемость и гибкость:
   - Prometheus и Grafana обладают возможностью горизонтального масштабирования, что позволяет обрабатывать большие объемы метрик в распределенной среде.
   - Возможность расширения функционала за счет подключения дополнительных экспортеров и плагинов.
   ```

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
